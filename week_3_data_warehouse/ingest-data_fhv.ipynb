{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cfc0faa",
   "metadata": {},
   "source": [
    "# Data Engineering Zoomcamp - Week 3: Inspect fhv data\n",
    "\n",
    "This notbook is part of the Data Engineering Zoomcamp 2023 and explores the dataset needed for the week3 homework as specified [here](../../homework.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7e4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                             # to help with dataframes\n",
    "import os                                       # to help with system calls\n",
    "from sqlalchemy import create_engine            # to help with named arguments\n",
    "from time import time                           # to help with timing\n",
    "import unittest                                 # to help with unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05dd7e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07269e03",
   "metadata": {},
   "source": [
    "## Step 1: Import Data\n",
    "\n",
    "We import the `fhv_tripdata_2019-01.csv.gz` we downloaded beforehand using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d1f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhv_url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-01.csv.gz\"\n",
    "peak_df = pd.read_csv(\"data/fhv/fhv_tripdata_2019-01.csv.gz\", nrows=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b955fdf5",
   "metadata": {},
   "source": [
    "## Step 2: Explore and prepare data\n",
    "\n",
    "Now we take a look at the column typed and clean the data where necessary\n",
    "\n",
    "- we see that columns 2 and three are dates and we will use the dtypes argument in read_csv to convert them to in our flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ea2918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>2019-01-01 02:51:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>2019-01-01 00:54:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>2019-01-01 00:54:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:19:00</td>\n",
       "      <td>2019-01-01 00:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:27:00</td>\n",
       "      <td>2019-01-01 00:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>B00248</td>\n",
       "      <td>2019-01-01 00:11:09</td>\n",
       "      <td>2019-01-01 00:20:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>B00248</td>\n",
       "      <td>2019-01-01 00:52:34</td>\n",
       "      <td>2019-01-01 01:01:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>B00248</td>\n",
       "      <td>2019-01-01 00:17:44</td>\n",
       "      <td>2019-01-01 00:24:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>B00248</td>\n",
       "      <td>2019-01-01 00:00:10</td>\n",
       "      <td>2019-01-01 00:33:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B00248</td>\n",
       "      <td>2019-01-01 00:06:00</td>\n",
       "      <td>2019-01-01 00:36:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0                B00001  2019-01-01 00:30:00  2019-01-01 02:51:55   \n",
       "1                B00001  2019-01-01 00:45:00  2019-01-01 00:54:49   \n",
       "2                B00001  2019-01-01 00:15:00  2019-01-01 00:54:52   \n",
       "3                B00008  2019-01-01 00:19:00  2019-01-01 00:39:00   \n",
       "4                B00008  2019-01-01 00:27:00  2019-01-01 00:37:00   \n",
       "..                  ...                  ...                  ...   \n",
       "95               B00248  2019-01-01 00:11:09  2019-01-01 00:20:59   \n",
       "96               B00248  2019-01-01 00:52:34  2019-01-01 01:01:06   \n",
       "97               B00248  2019-01-01 00:17:44  2019-01-01 00:24:03   \n",
       "98               B00248  2019-01-01 00:00:10  2019-01-01 00:33:26   \n",
       "99               B00248  2019-01-01 00:06:00  2019-01-01 00:36:23   \n",
       "\n",
       "    PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0            NaN           NaN      NaN                 B00001  \n",
       "1            NaN           NaN      NaN                 B00001  \n",
       "2            NaN           NaN      NaN                 B00001  \n",
       "3            NaN           NaN      NaN                 B00008  \n",
       "4            NaN           NaN      NaN                 B00008  \n",
       "..           ...           ...      ...                    ...  \n",
       "95           NaN         265.0      NaN                 B00248  \n",
       "96           NaN         265.0      NaN                 B00248  \n",
       "97           NaN         265.0      NaN                 B00248  \n",
       "98           NaN         265.0      NaN                 B00248  \n",
       "99           NaN         265.0      NaN                 B00248  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_df.head(n = 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3faab5fb",
   "metadata": {},
   "source": [
    "### explore column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bbe70f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   dispatching_base_num    100 non-null    object \n",
      " 1   pickup_datetime         100 non-null    object \n",
      " 2   dropOff_datetime        100 non-null    object \n",
      " 3   PUlocationID            0 non-null      float64\n",
      " 4   DOlocationID            74 non-null     float64\n",
      " 5   SR_Flag                 0 non-null      float64\n",
      " 6   Affiliated_base_number  100 non-null    object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# explore data\n",
    "# peak_df.shape    # number of rows and columns\n",
    "# peak_df.columns  # column names\n",
    "# peak_df.dtypes   # column types\n",
    "peak_df.info()   # index, column names, non-null counts and memory usage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
