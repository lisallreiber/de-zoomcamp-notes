{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cfc0faa",
   "metadata": {},
   "source": [
    "# Data Engineering Zoomcamp - Week 1: Upload Data to Postgres (Homework edition)\n",
    "\n",
    "This notbook is part of the Data Engineering Zoomcamp 2023 and explores the dataset needed for the week1 homework as specified [here](../homework.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7e4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                             # to help with dataframes\n",
    "import os                                       # to help with system calls\n",
    "from sqlalchemy import create_engine            # to help with named arguments\n",
    "from time import time                           # to help with timing\n",
    "import unittest                                 # to help with unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05dd7e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07269e03",
   "metadata": {},
   "source": [
    "## Step 1: Import Data\n",
    "\n",
    "We import the `green_tripdata_2019-01.csv.gz` we downloaded beforehand using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d1f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_df = pd.read_csv('green_tripdata_2019-01.csv.gz', parse_dates=[\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\"], nrows=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b955fdf5",
   "metadata": {},
   "source": [
    "## Step 2: Explore and prepare data\n",
    "\n",
    "Now we take a look at the column typed and clean the data where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ea2918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 15:17:29</td>\n",
       "      <td>2018-12-21 15:18:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:10:16</td>\n",
       "      <td>2019-01-01 00:16:32</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:27:11</td>\n",
       "      <td>2019-01-01 00:31:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:46:20</td>\n",
       "      <td>2019-01-01 01:04:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:19:06</td>\n",
       "      <td>2019-01-01 00:39:43</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>4.53</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2018-12-21 15:17:29   2018-12-21 15:18:57                  N   \n",
       "1         2  2019-01-01 00:10:16   2019-01-01 00:16:32                  N   \n",
       "2         2  2019-01-01 00:27:11   2019-01-01 00:31:38                  N   \n",
       "3         2  2019-01-01 00:46:20   2019-01-01 01:04:54                  N   \n",
       "4         2  2019-01-01 00:19:06   2019-01-01 00:39:43                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1           264           264                5           0.00   \n",
       "1           1            97            49                2           0.86   \n",
       "2           1            49           189                2           0.66   \n",
       "3           1           189            17                2           2.68   \n",
       "4           1            82           258                1           4.53   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          3.0    0.5      0.5        0.00           0.0        NaN   \n",
       "1          6.0    0.5      0.5        0.00           0.0        NaN   \n",
       "2          4.5    0.5      0.5        0.00           0.0        NaN   \n",
       "3         13.5    0.5      0.5        2.96           0.0        NaN   \n",
       "4         18.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          4.30             2          1   \n",
       "1                    0.3          7.30             2          1   \n",
       "2                    0.3          5.80             1          1   \n",
       "3                    0.3         19.71             1          1   \n",
       "4                    0.3         19.30             2          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3faab5fb",
   "metadata": {},
   "source": [
    "### explore column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bbe70f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               100 non-null    int64         \n",
      " 1   lpep_pickup_datetime   100 non-null    datetime64[ns]\n",
      " 2   lpep_dropoff_datetime  100 non-null    datetime64[ns]\n",
      " 3   store_and_fwd_flag     100 non-null    object        \n",
      " 4   RatecodeID             100 non-null    int64         \n",
      " 5   PULocationID           100 non-null    int64         \n",
      " 6   DOLocationID           100 non-null    int64         \n",
      " 7   passenger_count        100 non-null    int64         \n",
      " 8   trip_distance          100 non-null    float64       \n",
      " 9   fare_amount            100 non-null    float64       \n",
      " 10  extra                  100 non-null    float64       \n",
      " 11  mta_tax                100 non-null    float64       \n",
      " 12  tip_amount             100 non-null    float64       \n",
      " 13  tolls_amount           100 non-null    float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  100 non-null    float64       \n",
      " 16  total_amount           100 non-null    float64       \n",
      " 17  payment_type           100 non-null    int64         \n",
      " 18  trip_type              100 non-null    int64         \n",
      " 19  congestion_surcharge   0 non-null      float64       \n",
      "dtypes: datetime64[ns](2), float64(10), int64(7), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# explore data\n",
    "# peak_df.shape    # number of rows and columns\n",
    "# peak_df.columns  # column names\n",
    "# peak_df.dtypes   # column types\n",
    "peak_df.info()   # index, column names, non-null counts and memory usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8712728d",
   "metadata": {},
   "source": [
    "## Step 3: Load taxi rides data into postgres database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa73de71",
   "metadata": {},
   "source": [
    "### 3.1 connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339a5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to postgres\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c43ef54c",
   "metadata": {},
   "source": [
    "### 3.2: importing data in chunkes into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de7b9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this purpose we can use the iterator argument from the pandas.read_csv function\n",
    "# tip: press shift+tab to see help\n",
    "df_iter = pd.read_csv('green_tripdata_2019-01.csv.gz', parse_dates=[\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\"], iterator=True, chunksize=100000)\n",
    "df = next(df_iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12201f3a",
   "metadata": {},
   "source": [
    "### 3.3: writing the data into the database in batches\n",
    "\n",
    "the dataset is potentially too big to write it into the postgres database all in one piece, therefore we batch it and load each chunk separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "791b0846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the table schema into the DB\n",
    "df.head(n=0).to_sql(name='green_taxi_data', con=engine, if_exists='replace')\n",
    "df.to_sql(name='green_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91de79d0",
   "metadata": {},
   "source": [
    "*now we can check in the terminal (with pgcli) or in pgAdmin if the green_taxi table exists*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cd464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 15.591 seconds\n",
      "inserted another chunk, took 15.564 seconds\n",
      "inserted another chunk, took 15.485 seconds\n",
      "inserted another chunk, took 14.941 seconds\n",
      "inserted another chunk, took 15.135 seconds\n",
      "inserted another chunk, took 5.144 seconds\n",
      "Finished ingesting data into the postgres database\n"
     ]
    }
   ],
   "source": [
    "# next returns TRUE as long as there is a next iteration, if there isn't it returns FALSE\n",
    "while True:\n",
    "    try: \n",
    "        t_start = time()\n",
    "\n",
    "        df = next(df_iter)\n",
    "\n",
    "        #df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "        #df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        \n",
    "        df.to_sql(name='green_taxi_data', con=engine, if_exists='append')\n",
    "\n",
    "        t_end = time()\n",
    "\n",
    "        print('inserted another chunk, took %.3f seconds' % (t_end - t_start))\n",
    "        \n",
    "    except StopIteration:\n",
    "            print(\"Finished ingesting data into the postgres database\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd398462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    count\n",
      "0  630918\n"
     ]
    }
   ],
   "source": [
    "# check if the data was ingested correctly\n",
    "print(pd.read_sql(\"SELECT COUNT(*) FROM green_taxi_data\", engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "146959f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630918\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in the csv with pandas\n",
    "print(len(pd.read_csv('green_tripdata_2019-01.csv.gz')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc79df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write unit test\n",
    "class TestIngestData(unittest.TestCase):\n",
    "    def test_ingest_data(self):\n",
    "        # check if the data was ingested correctly\n",
    "        self.assertEqual(pd.read_sql(\"SELECT COUNT(*) FROM green_taxi_data\", engine).values[0][0], len(pd.read_csv('green_tripdata_2019-01.csv.gz')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3b55d93",
   "metadata": {},
   "source": [
    "## Step 4: Load Taxi Zones Data into postgres database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf422a35",
   "metadata": {},
   "source": [
    "this time we only download the data if they do not already exist (-nc flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2178a11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘./taxi_zone_lookup.csv’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget -O ./taxi_zone_lookup.csv --no-clobber https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdefce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv('taxi_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c99e27b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5134c2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
